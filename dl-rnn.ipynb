{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef0a0724",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-28T17:20:44.689150Z",
     "iopub.status.busy": "2023-04-28T17:20:44.688608Z",
     "iopub.status.idle": "2023-04-28T17:20:44.787677Z",
     "shell.execute_reply": "2023-04-28T17:20:44.786347Z"
    },
    "papermill": {
     "duration": 0.111135,
     "end_time": "2023-04-28T17:20:44.790864",
     "exception": false,
     "start_time": "2023-04-28T17:20:44.679729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/aksharantar/aksharantar_sampled/brx/brx_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/brx/brx_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/brx/brx_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/tam/tam_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/tam/tam_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/tam/tam_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/mni/mni_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/mni/mni_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/mni/mni_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/urd/urd_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/urd/urd_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/urd/urd_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/kok/kok_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/kok/kok_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/kok/kok_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/mai/mai_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/mai/mai_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/mai/mai_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/guj/guj_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/guj/guj_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/guj/guj_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/ben/ben_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/ben/ben_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/ben/ben_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/tel/tel_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/tel/tel_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/tel/tel_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/kas/kas_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/kas/kas_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/kas/kas_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/kan/kan_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/kan/kan_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/kan/kan_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/mal/mal_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/mal/mal_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/mal/mal_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/pan/pan_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/pan/pan_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/pan/pan_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/asm/asm_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/asm/asm_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/asm/asm_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/sid/sid_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/sid/sid_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/sid/sid_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/mar/mar_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/mar/mar_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/mar/mar_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/san/san_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/san/san_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/san/san_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_valid.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/ori/ori_test.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/ori/ori_train.csv\n",
      "/kaggle/input/aksharantar/aksharantar_sampled/ori/ori_valid.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82ba0cba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:20:44.804907Z",
     "iopub.status.busy": "2023-04-28T17:20:44.804126Z",
     "iopub.status.idle": "2023-04-28T17:20:46.969568Z",
     "shell.execute_reply": "2023-04-28T17:20:46.968354Z"
    },
    "papermill": {
     "duration": 2.175715,
     "end_time": "2023-04-28T17:20:46.972525",
     "exception": false,
     "start_time": "2023-04-28T17:20:44.796810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Instantiates the device to be used as GPU/CPU based on availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f659af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:20:46.986182Z",
     "iopub.status.busy": "2023-04-28T17:20:46.985595Z",
     "iopub.status.idle": "2023-04-28T17:20:46.993765Z",
     "shell.execute_reply": "2023-04-28T17:20:46.992699Z"
    },
    "papermill": {
     "duration": 0.017957,
     "end_time": "2023-04-28T17:20:46.996280",
     "exception": false,
     "start_time": "2023-04-28T17:20:46.978323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mal_embedd_size = 24\n",
    "eng_embedd_size = 31\n",
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e88d6720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:20:47.010503Z",
     "iopub.status.busy": "2023-04-28T17:20:47.009691Z",
     "iopub.status.idle": "2023-04-28T17:20:49.770297Z",
     "shell.execute_reply": "2023-04-28T17:20:49.769169Z"
    },
    "papermill": {
     "duration": 2.770794,
     "end_time": "2023-04-28T17:20:49.773145",
     "exception": false,
     "start_time": "2023-04-28T17:20:47.002351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.loadtxt(\"/kaggle/input/aksharantar/aksharantar_sampled/mal/mal_train.csv\",\n",
    "                 delimiter=\",\", dtype=str)\n",
    "num_sample = arr.shape[0]\n",
    "x_train,y_train = arr[:,0],arr[:,1]\n",
    "X = np.zeros((num_sample,eng_embedd_size))\n",
    "y = np.zeros((num_sample,mal_embedd_size))\n",
    "english_index = 3\n",
    "mal_index = 3\n",
    "english_dict = {}\n",
    "malayalam_dict = {}\n",
    "english_index_dict = {}\n",
    "malayalam_index_dict = {}\n",
    "\n",
    "for i in range(num_sample):\n",
    "    \n",
    "    X[i][0] = 1\n",
    "    y[i][0] = 1\n",
    "    for j in range(1,len(x_train[i])):\n",
    "        \n",
    "        if(english_dict.get(x_train[i][j]) == None):\n",
    "            english_dict[x_train[i][j]]=english_index\n",
    "            english_index_dict[english_index] = x_train[i][j]\n",
    "            english_index+=1\n",
    "            \n",
    "            \n",
    "        X[i][j+1] = english_dict[x_train[i][j]]\n",
    "    \n",
    "    X[i][len(x_train[i])]=2\n",
    "        \n",
    "    for j in range(len(y_train[i])):\n",
    "            \n",
    "        if(malayalam_dict.get(y_train[i][j]) == None):\n",
    "            malayalam_dict[y_train[i][j]]=mal_index\n",
    "            malayalam_index_dict[mal_index] = y_train[i][j]\n",
    "            mal_index+=1\n",
    "        y[i][j+1] = malayalam_dict[y_train[i][j]]\n",
    "        \n",
    "    y[i][len(y_train[i])] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf74dc",
   "metadata": {
    "papermill": {
     "duration": 0.006284,
     "end_time": "2023-04-28T17:20:49.785669",
     "exception": false,
     "start_time": "2023-04-28T17:20:49.779385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69d9f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:20:49.799373Z",
     "iopub.status.busy": "2023-04-28T17:20:49.798917Z",
     "iopub.status.idle": "2023-04-28T17:20:49.806081Z",
     "shell.execute_reply": "2023-04-28T17:20:49.804772Z"
    },
    "papermill": {
     "duration": 0.017328,
     "end_time": "2023-04-28T17:20:49.808790",
     "exception": false,
     "start_time": "2023-04-28T17:20:49.791462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MakeDataset(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = torch.tensor(x,dtype=torch.int64)\n",
    "        self.y = torch.tensor(y,dtype=torch.int64)\n",
    "        self.len = x.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "426b40d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:20:49.822316Z",
     "iopub.status.busy": "2023-04-28T17:20:49.821909Z",
     "iopub.status.idle": "2023-04-28T17:20:49.872586Z",
     "shell.execute_reply": "2023-04-28T17:20:49.871248Z"
    },
    "papermill": {
     "duration": 0.060912,
     "end_time": "2023-04-28T17:20:49.875762",
     "exception": false,
     "start_time": "2023-04-28T17:20:49.814850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = MakeDataset(X,y)\n",
    "train_loader = DataLoader(dataset,shuffle=True,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee750223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:20:49.890009Z",
     "iopub.status.busy": "2023-04-28T17:20:49.889134Z",
     "iopub.status.idle": "2023-04-28T17:20:49.903072Z",
     "shell.execute_reply": "2023-04-28T17:20:49.902035Z"
    },
    "papermill": {
     "duration": 0.024172,
     "end_time": "2023-04-28T17:20:49.905743",
     "exception": false,
     "start_time": "2023-04-28T17:20:49.881571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    Simple RNN based encoder network\n",
    "    '''\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim ,\n",
    "                    rnn_type = 'lstm',\n",
    "                    layers = 2,\n",
    "                    bidirectional = False,\n",
    "                    dropout = 0,\n",
    "                    device = device\n",
    "                ):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.detail_parameters = {\n",
    "            'input_dim' : input_dim,\n",
    "            'embed_dim' : embed_dim,\n",
    "            'hidden_dim' : hidden_dim,\n",
    "            'rnn_type' : rnn_type,\n",
    "            'layers' : layers,\n",
    "            'directions' : 2 if bidirectional else 1,\n",
    "            'device' : device.type,\n",
    "        }\n",
    "        \n",
    "        self.input_dim = input_dim #src_vocab_sz\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn_type = rnn_type\n",
    "        self.layers = layers\n",
    "        self.directions = 2 if bidirectional else 1\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_dim, self.embed_dim)\n",
    "\n",
    "        if self.rnn_type == 'rnn':\n",
    "            self.enc_rnn = nn.RNN(input_size= self.embed_dim,\n",
    "                          hidden_size= self.hidden_dim,\n",
    "                          num_layers= self.layers,\n",
    "                          bidirectional= bidirectional)\n",
    "            \n",
    "        elif self.rnn_type == \"gru\":\n",
    "            self.enc_rnn = nn.GRU(input_size= self.enc_embed_dim,\n",
    "                          hidden_size= self.enc_hidden_dim,\n",
    "                          num_layers= self.enc_layers,\n",
    "                          bidirectional= bidirectional)\n",
    "        elif self.rnn_type == \"lstm\":\n",
    "            self.enc_rnn = nn.LSTM(input_size= self.enc_embed_dim,\n",
    "                          hidden_size= self.enc_hidden_dim,\n",
    "                          num_layers= self.enc_layers,\n",
    "                          bidirectional= bidirectional)\n",
    "        else:\n",
    "            raise Exception(\"unknown RNN type mentioned\")\n",
    "            \n",
    "            \n",
    "    def forward(self, input, hidden):\n",
    "        # Convert input sequence to embeddings\n",
    "\n",
    "        embedded = self.embedding(input)\n",
    "\n",
    "        output, hidden = self.enc_rnn(embedded, hidden)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def getParams(self):\n",
    "        return self.detail_parameters\n",
    "    \n",
    "    def init_hidden(self, batch):\n",
    "        # Initialize the hidden state to zeros\n",
    "        return torch.zeros(self.layers,batch,self.hidden_dim,device=device)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684d34b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:20:49.919227Z",
     "iopub.status.busy": "2023-04-28T17:20:49.918780Z",
     "iopub.status.idle": "2023-04-28T17:20:49.923526Z",
     "shell.execute_reply": "2023-04-28T17:20:49.922236Z"
    },
    "papermill": {
     "duration": 0.014451,
     "end_time": "2023-04-28T17:20:49.925956",
     "exception": false,
     "start_time": "2023-04-28T17:20:49.911505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a,b = next(iter(train_loader))\n",
    "# enc = Encoder(27,64,64)\n",
    "# o,h=enc.forward(a[:10,:].T,enc.init_hidden(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f099670a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:20:49.939861Z",
     "iopub.status.busy": "2023-04-28T17:20:49.939038Z",
     "iopub.status.idle": "2023-04-28T17:20:49.953687Z",
     "shell.execute_reply": "2023-04-28T17:20:49.952482Z"
    },
    "papermill": {
     "duration": 0.02466,
     "end_time": "2023-04-28T17:20:49.956321",
     "exception": false,
     "start_time": "2023-04-28T17:20:49.931661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    Used as decoder stage\n",
    "    '''\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim,\n",
    "                    rnn_type = 'lstm',\n",
    "                    layers = 2,\n",
    "                    use_attention = False,\n",
    "                    outstate_dim = None,\n",
    "                    dropout = 0,\n",
    "                    device = device\n",
    "                 ):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.detail_parameters = {\n",
    "            'input_dim' : input_dim,\n",
    "            'embed_dim' : embed_dim,\n",
    "            'hidden_dim' : hidden_dim,\n",
    "            'rnn_type' : rnn_type,\n",
    "            'layers' : layers,\n",
    "            'device' : device.type\n",
    "        }\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.rnn_type = rnn_type\n",
    "        self.layers = layers\n",
    "        self.use_attention = use_attention\n",
    "        self.device = device\n",
    "        if self.use_attention:\n",
    "            self.outstate_dim = outstate_dim if outstate_dim else hidden_dim\n",
    "        else:\n",
    "            self.outstate_dim = 0\n",
    "\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_dim, self.embed_dim)\n",
    "    \n",
    "        self.softmax = F.softmax\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.embed_dim), nn.LeakyReLU(),\n",
    "            nn.Linear(self.embed_dim, self.input_dim),\n",
    "            )\n",
    "\n",
    "        if self.rnn_type == 'rnn':\n",
    "            self.dec_rnn = nn.RNN(input_size= self.embed_dim,\n",
    "                                  \n",
    "                          hidden_size= self.hidden_dim, # previous Hidden\n",
    "                          num_layers= self.layers,)\n",
    "        elif self.rnn_type == 'gru':\n",
    "            self.dec_rnn = nn.GRU(input_size= self.embed_dim + self.outstate_dim, # to concat attention_output\n",
    "                          hidden_size= self.hidden_dim, # previous Hidden\n",
    "                          num_layers= self.layers,\n",
    "                          batch_first = True )\n",
    "        elif self.rnn_type == \"lstm\":\n",
    "            self.dec_rnn = nn.LSTM(input_size= self.embed_dim + self.outstate_dim, # to concat attention_output\n",
    "                          hidden_size= self.hidden_dim, # previous Hidden\n",
    "                          num_layers= self.layers,\n",
    "                          batch_first = True )\n",
    "        else:\n",
    "            raise Exception(\"unknown RNN type mentioned\")\n",
    "\n",
    "\n",
    "    def getParams(self):\n",
    "        return self.detail_parameters\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "#         print(hidden.shape)\n",
    "        output = self.embedding(input)\n",
    "\n",
    "        output, hidden = self.dec_rnn(output, hidden)\n",
    "\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b3879b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:20:49.970258Z",
     "iopub.status.busy": "2023-04-28T17:20:49.969431Z",
     "iopub.status.idle": "2023-04-28T17:20:49.974600Z",
     "shell.execute_reply": "2023-04-28T17:20:49.973652Z"
    },
    "papermill": {
     "duration": 0.015049,
     "end_time": "2023-04-28T17:20:49.977145",
     "exception": false,
     "start_time": "2023-04-28T17:20:49.962096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ob = Decoder(70,64,64)\n",
    "# s,d = ob.forward(b[:10,:].T,h)\n",
    "# s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0440255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:20:49.991458Z",
     "iopub.status.busy": "2023-04-28T17:20:49.990653Z",
     "iopub.status.idle": "2023-04-28T17:20:50.006791Z",
     "shell.execute_reply": "2023-04-28T17:20:50.005788Z"
    },
    "papermill": {
     "duration": 0.02633,
     "end_time": "2023-04-28T17:20:50.009383",
     "exception": false,
     "start_time": "2023-04-28T17:20:49.983053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_seq_length = 31,\n",
    "                 output_seq_length = 24,\n",
    "                 enc_input_dim = 29, \n",
    "                 dec_input_dim = 72,\n",
    "                 enc_hidden_dim = 64, \n",
    "                 dec_hidden_dim =64,\n",
    "                 enc_embed_dim = 64, \n",
    "                 dec_embed_dim = 64, \n",
    "                 bidirectional = False,\n",
    "                 layers = 2,\n",
    "                 rnn_type = 'rnn', \n",
    "                 dropout = 0, \n",
    "                 device = device\n",
    "                ):\n",
    "        \n",
    "        \n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.detail_parameters = {\n",
    "         'input_seq_length': input_seq_length,\n",
    "         'output_seq_length' : output_seq_length,\n",
    "         'enc_input_dim' : enc_input_dim, \n",
    "         'dec_input_dim' : dec_input_dim,\n",
    "         'enc_embed_dim' : enc_embed_dim, \n",
    "         'dec_embed_dim' : dec_embed_dim, \n",
    "         'bidirectional' : bidirectional,\n",
    "         'layers' : layers,\n",
    "         'rnn_type' :rnn_type, \n",
    "         'dropout' : dropout, \n",
    "         'device' : device.type\n",
    "        }\n",
    "        self.input_seq_length = input_seq_length\n",
    "        self.output_seq_length = output_seq_length\n",
    "        self.enc_input_dim = enc_input_dim\n",
    "        self.dec_input_dim = dec_input_dim\n",
    "        self.enc_hidden_dim = enc_hidden_dim\n",
    "        self.dec_hidden_dim = dec_hidden_dim\n",
    "        self.enc_embed_dim = enc_embed_dim\n",
    "        self.dec_embed_dim = dec_embed_dim \n",
    "        self.direction = bidirectional\n",
    "        self.layers = layers\n",
    "        self.rnn_type = rnn_type \n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "        self.softmax = F.softmax\n",
    "        \n",
    "        self.encoder = Encoder(input_dim = self.enc_input_dim,\n",
    "                               embed_dim = self.enc_embed_dim, \n",
    "                               hidden_dim =  self.enc_hidden_dim,\n",
    "                               rnn_type = self.rnn_type,\n",
    "                               layers = self.layers,\n",
    "                               bidirectional = self.direction,\n",
    "                               dropout = self.dropout, \n",
    "                               device = self.device\n",
    "                              )\n",
    "        self.decoder = Decoder(\n",
    "                               input_dim = self.dec_input_dim,\n",
    "                               embed_dim = self.dec_embed_dim,\n",
    "                               hidden_dim = self.enc_hidden_dim,\n",
    "                               rnn_type = self.rnn_type,\n",
    "                               layers = self.layers,\n",
    "                               dropout = self.dropout, \n",
    "                               device = self.device\n",
    "                               )\n",
    "        \n",
    "    def getParams(self):\n",
    "        return self.detail_parameters\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        batch_size = input.shape[0]\n",
    "        \n",
    "        enc_hidden = self.encoder.init_hidden(batch_size)\n",
    "        \n",
    "        enc_output,enc_last_state = self.encoder.forward(input.T, enc_hidden)\n",
    "\n",
    "        \n",
    "        predicted = torch.zeros(self.output_seq_length, batch_size, self.dec_input_dim,device = self.device)\n",
    "        \n",
    "        \n",
    "        dec_hidden = enc_last_state\n",
    "        \n",
    "        output = torch.ones(1,batch_size,dtype=torch.long, device=self.device)\n",
    "        \n",
    "        for t in range(self.output_seq_length-1):\n",
    "            output,dec_hidden=self.decoder.forward(output,dec_hidden)\n",
    "            predicted[t] = output\n",
    "#             print(output.shape)\n",
    "            output = self.softmax(output,dim=2)\n",
    "            output = torch.argmax(output,dim=2)\n",
    "#             print(output.shape)\n",
    "            \n",
    "\n",
    "        return predicted\n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e9e79c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:20:50.023057Z",
     "iopub.status.busy": "2023-04-28T17:20:50.022250Z",
     "iopub.status.idle": "2023-04-28T17:34:05.593104Z",
     "shell.execute_reply": "2023-04-28T17:34:05.592066Z"
    },
    "papermill": {
     "duration": 795.589675,
     "end_time": "2023-04-28T17:34:05.604734",
     "exception": false,
     "start_time": "2023-04-28T17:20:50.015059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:20<06:21, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 => loss = 498.88017559051514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:45<06:53, 22.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 => loss = 430.21292519569397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:08<06:35, 23.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 => loss = 429.1843934059143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:32<06:15, 23.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 => loss = 428.8622717857361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:57<06:01, 24.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 => loss = 428.6876871585846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [02:25<05:53, 25.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 => loss = 428.533340215683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [02:56<05:53, 27.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 => loss = 428.2436375617981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [03:30<05:54, 29.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 => loss = 428.2426030635834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [04:09<05:57, 32.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 => loss = 428.1091775894165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [04:51<05:52, 35.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 => loss = 427.9767920970917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [05:34<05:40, 37.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 => loss = 428.21408772468567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [06:20<05:21, 40.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 => loss = 428.02984833717346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [07:04<04:49, 41.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 => loss = 428.00564432144165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [07:47<04:10, 41.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 => loss = 430.8917660713196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [08:36<03:40, 44.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 => loss = 429.19998121261597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [09:27<03:04, 46.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 => loss = 428.2736840248108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [10:22<02:25, 48.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 => loss = 427.9791452884674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [11:20<01:42, 51.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 => loss = 427.9525020122528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [12:18<00:53, 53.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 => loss = 427.7858328819275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [13:15<00:00, 39.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 => loss = 427.7225983142853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq()\n",
    "model.to(device)\n",
    "epochs = 20\n",
    "def train(data_loader, epochs):\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # set model to train mode\n",
    "        model.train()\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            total_loss=0\n",
    "            for i, (source, target) in enumerate(data_loader):\n",
    "\n",
    "                source = source.to(device)\n",
    "                target = target.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                output = model.forward(source)  # exclude last token from target sequence\n",
    "                output = output.permute(1, 0, 2)\n",
    "                \n",
    "                output = output.reshape(-1, 72)\n",
    "                target = target.reshape(-1)\n",
    "\n",
    "                loss = criterion(output, target)  # calculate loss\n",
    "                \n",
    "                loss.backward()  # compute gradients\n",
    "                optimizer.step()  # update parameters\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                \n",
    "            print(f'epoch {epoch} => loss = {total_loss}')\n",
    "\n",
    "train(train_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0694c11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:34:05.625922Z",
     "iopub.status.busy": "2023-04-28T17:34:05.625104Z",
     "iopub.status.idle": "2023-04-28T17:34:12.747202Z",
     "shell.execute_reply": "2023-04-28T17:34:12.745740Z"
    },
    "papermill": {
     "duration": 7.135242,
     "end_time": "2023-04-28T17:34:12.749784",
     "exception": false,
     "start_time": "2023-04-28T17:34:05.614542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51200, 24])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def printOutput(y):\n",
    "    s=''\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 0 or y[i] == 1 or y[i] == 2:\n",
    "            continue\n",
    "        s+=malayalam_index_dict[y[i]]\n",
    "    return s\n",
    "\n",
    "def accuracy(y_dash , y):\n",
    "    num_sample,index = y_dash.shape\n",
    "    score = 0\n",
    "    for i in range(num_sample):\n",
    "        flag = 0\n",
    "        for j in range(index):\n",
    "            if y_dash[i][j] !=  y[i][j]:\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            score+=1\n",
    "    return score/num_sample\n",
    "\n",
    "\n",
    "output = model.forward(train_loader.dataset.x)\n",
    "\n",
    "output = output.permute(1, 0, 2)\n",
    "\n",
    "output = F.softmax(output,dim=2)\n",
    "output = torch.argmax(output,dim=2)\n",
    "output.shape\n",
    "# train_loader.dataset.x[0].unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85ea3f5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:34:12.769360Z",
     "iopub.status.busy": "2023-04-28T17:34:12.768533Z",
     "iopub.status.idle": "2023-04-28T17:34:12.778436Z",
     "shell.execute_reply": "2023-04-28T17:34:12.777209Z"
    },
    "papermill": {
     "duration": 0.022811,
     "end_time": "2023-04-28T17:34:12.781310",
     "exception": false,
     "start_time": "2023-04-28T17:34:12.758499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printOutput(train_loader.dataset.y[0])\n",
    "accuracy(output.T,train_loader.dataset.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc0319c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:34:12.801278Z",
     "iopub.status.busy": "2023-04-28T17:34:12.800840Z",
     "iopub.status.idle": "2023-04-28T17:34:12.809789Z",
     "shell.execute_reply": "2023-04-28T17:34:12.808840Z"
    },
    "papermill": {
     "duration": 0.021785,
     "end_time": "2023-04-28T17:34:12.812035",
     "exception": false,
     "start_time": "2023-04-28T17:34:12.790250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 28,  7,  6,  6,  6,  6,  6,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  3,  4,  5,  6,  5,  7,  8,  9, 10,  6, 10,  7,  8,  5,  6,  5,  7,\n",
       "        11,  2,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output[0])\n",
    "train_loader.dataset.y[0]\n",
    "#     print(name, type(param))\n",
    "# for (i,j) in param:\n",
    "#     print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65794336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:34:12.832732Z",
     "iopub.status.busy": "2023-04-28T17:34:12.832336Z",
     "iopub.status.idle": "2023-04-28T17:34:12.842557Z",
     "shell.execute_reply": "2023-04-28T17:34:12.841603Z"
    },
    "papermill": {
     "duration": 0.023654,
     "end_time": "2023-04-28T17:34:12.844839",
     "exception": false,
     "start_time": "2023-04-28T17:34:12.821185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'പി്്്്്്'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def printOutput(y):\n",
    "    s=''\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 0 or y[i] == 1 or y[i] == 2:\n",
    "            continue\n",
    "        s+=malayalam_index_dict[y[i]]\n",
    "    return s\n",
    "\n",
    "printOutput(train_loader.dataset.y[0].detach().cpu().numpy())\n",
    "printOutput(output[0].detach().cpu().numpy())\n",
    "# malayalam_index_dict[train_loader.dataset.y[0][1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0c20005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T17:34:12.865014Z",
     "iopub.status.busy": "2023-04-28T17:34:12.864582Z",
     "iopub.status.idle": "2023-04-28T17:34:12.869297Z",
     "shell.execute_reply": "2023-04-28T17:34:12.868109Z"
    },
    "papermill": {
     "duration": 0.017653,
     "end_time": "2023-04-28T17:34:12.871769",
     "exception": false,
     "start_time": "2023-04-28T17:34:12.854116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a,b = next(iter(train_loader))\n",
    "# a.shape\n",
    "\n",
    "# train_loader.dataset.x[0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259fc1c0",
   "metadata": {
    "papermill": {
     "duration": 0.008758,
     "end_time": "2023-04-28T17:34:12.889519",
     "exception": false,
     "start_time": "2023-04-28T17:34:12.880761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 819.627793,
   "end_time": "2023-04-28T17:34:14.125468",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-28T17:20:34.497675",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
