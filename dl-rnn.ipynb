{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nclear = lambda: os.system('clear')\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-17T10:03:14.861408Z","iopub.execute_input":"2023-05-17T10:03:14.862272Z","iopub.status.idle":"2023-05-17T10:03:14.895732Z","shell.execute_reply.started":"2023-05-17T10:03:14.862236Z","shell.execute_reply":"2023-05-17T10:03:14.894809Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/anjali/AnjaliOldLipi-Regular.woff\n/kaggle/input/anjali/AnjaliOldLipi-Regular.woff2\n/kaggle/input/anjali/AnjaliOldLipi-Regular.ttf\n/kaggle/input/aksharantar/aksharantar_sampled/brx/brx_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/brx/brx_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/brx/brx_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/tam/tam_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/tam/tam_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/tam/tam_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/mni/mni_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/mni/mni_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/mni/mni_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/urd/urd_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/urd/urd_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/urd/urd_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/kok/kok_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/kok/kok_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/kok/kok_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/mai/mai_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/mai/mai_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/mai/mai_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/guj/guj_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/guj/guj_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/guj/guj_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/ben/ben_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/ben/ben_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/ben/ben_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/tel/tel_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/tel/tel_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/tel/tel_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/kas/kas_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/kas/kas_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/kas/kas_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/kan/kan_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/kan/kan_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/kan/kan_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/mal/mal_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/mal/mal_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/mal/mal_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/pan/pan_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/pan/pan_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/pan/pan_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/asm/asm_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/asm/asm_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/asm/asm_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/sid/sid_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/sid/sid_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/sid/sid_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/mar/mar_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/mar/mar_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/mar/mar_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/san/san_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/san/san_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/san/san_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_valid.csv\n/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/ori/ori_test.csv\n/kaggle/input/aksharantar/aksharantar_sampled/ori/ori_train.csv\n/kaggle/input/aksharantar/aksharantar_sampled/ori/ori_valid.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### ALL NECESSARY IMPORTS","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader \n\nfrom tqdm import tqdm\nimport heapq\n\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.font_manager import FontProperties\n\nimport wandb\n# Instantiates the device to be used as GPU/CPU based on availability\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:03:18.583775Z","iopub.execute_input":"2023-05-17T10:03:18.584138Z","iopub.status.idle":"2023-05-17T10:03:23.294940Z","shell.execute_reply.started":"2023-05-17T10:03:18.584108Z","shell.execute_reply":"2023-05-17T10:03:23.293846Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"#specify max length of sequence\nmal_embedd_size = 29\neng_embedd_size = 32\ndevice.type","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:03:23.296818Z","iopub.execute_input":"2023-05-17T10:03:23.297147Z","iopub.status.idle":"2023-05-17T10:03:23.306724Z","shell.execute_reply.started":"2023-05-17T10:03:23.297116Z","shell.execute_reply":"2023-05-17T10:03:23.305730Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"### PREPROCESSING STEP","metadata":{}},{"cell_type":"code","source":"# Load Data to capture all characters\narr = np.loadtxt(\"/kaggle/input/aksharantar/aksharantar_sampled/mal/mal_train.csv\",\n                 delimiter=\",\", dtype=str)\nnum_sample = arr.shape[0]\nx_train,y_train = arr[:,0],arr[:,1]\nenglish_index = 3\nmal_index = 3\nenglish_dict = {}\nmalayalam_dict = {}\nenglish_index_dict = {}\nmalayalam_index_dict = {}\n\n# Create dictionary for malayalam and english\n\nfor i in range(num_sample):\n    for j in range(len(x_train[i])):\n        \n        if(english_dict.get(x_train[i][j]) == None):\n            english_dict[x_train[i][j]]=english_index\n            english_index_dict[english_index] = x_train[i][j]\n            english_index+=1\n        \n    for j in range(len(y_train[i])):\n            \n        if(malayalam_dict.get(y_train[i][j]) == None):\n            malayalam_dict[y_train[i][j]]=mal_index\n            malayalam_index_dict[mal_index] = y_train[i][j]\n            mal_index+=1","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:03:26.262465Z","iopub.execute_input":"2023-05-17T10:03:26.262850Z","iopub.status.idle":"2023-05-17T10:03:27.721156Z","shell.execute_reply.started":"2023-05-17T10:03:26.262814Z","shell.execute_reply":"2023-05-17T10:03:27.720094Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Adding start, stop and padding symbols\nmalayalam_index_dict[1] = '<S>'\nenglish_index_dict[1] = '<S>'\n\nmalayalam_index_dict[2] = '<E>'\nenglish_index_dict[2] = '<E>'\n\nmalayalam_index_dict[0] = '<P>'\nenglish_index_dict[0] = '<P>'","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:03:27.723120Z","iopub.execute_input":"2023-05-17T10:03:27.723500Z","iopub.status.idle":"2023-05-17T10:03:27.729638Z","shell.execute_reply.started":"2023-05-17T10:03:27.723466Z","shell.execute_reply":"2023-05-17T10:03:27.728617Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Function to load data from the data set and create and array corresponding to it\n\ndef loadData(PATH = \"/kaggle/input/aksharantar/aksharantar_sampled/mal/mal_test.csv\"):  \n    \n    arr = np.loadtxt(PATH,\n                 delimiter=\",\", dtype=str)\n    num_sample = arr.shape[0]\n    x,y = arr[:,0],arr[:,1]\n    X = np.zeros((num_sample,eng_embedd_size))\n    Y = np.zeros((num_sample,mal_embedd_size))\n\n    for i in range(num_sample):\n\n        X[i][0] = 1\n        Y[i][0] = 1\n        for j in range(len(x[i])):\n            if(english_dict.get(x[i][j]) != None):\n                X[i][j+1] = english_dict[x[i][j]]\n            else:\n                X[i][j+1] = 0\n\n        X[i][len(x[i])+1]=2\n\n        for j in range(len(y[i])):\n            if(malayalam_dict.get(y[i][j]) != None):\n                Y[i][j+1] = malayalam_dict[y[i][j]]\n            else:\n                Y[i][j+1] = 0\n\n        Y[i][len(y[i])+1] = 2\n        \n    return X, Y","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:03:27.731473Z","iopub.execute_input":"2023-05-17T10:03:27.732238Z","iopub.status.idle":"2023-05-17T10:03:27.743746Z","shell.execute_reply.started":"2023-05-17T10:03:27.732185Z","shell.execute_reply":"2023-05-17T10:03:27.742794Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Load all data with specified path\nX_train,y_train = loadData(PATH = \"/kaggle/input/aksharantar/aksharantar_sampled/mal/mal_train.csv\")\nX_val,y_val = loadData(PATH = \"/kaggle/input/aksharantar/aksharantar_sampled/mal/mal_valid.csv\")\nX_test,y_test = loadData(PATH = \"/kaggle/input/aksharantar/aksharantar_sampled/mal/mal_test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:03:30.477428Z","iopub.execute_input":"2023-05-17T10:03:30.478582Z","iopub.status.idle":"2023-05-17T10:03:34.670508Z","shell.execute_reply.started":"2023-05-17T10:03:30.478541Z","shell.execute_reply":"2023-05-17T10:03:34.669416Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Class to create dataset, so can be passed to pytorch dataloader\nclass MakeDataset(Dataset):\n    def __init__(self,x,y):\n        self.x = torch.tensor(x,dtype=torch.int64)\n        self.y = torch.tensor(y,dtype=torch.int64)\n        self.len = x.shape[0]\n\n    def __getitem__(self,idx):\n        return self.x[idx],self.y[idx]\n\n  \n    def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:03:34.972767Z","iopub.execute_input":"2023-05-17T10:03:34.973433Z","iopub.status.idle":"2023-05-17T10:03:34.980371Z","shell.execute_reply.started":"2023-05-17T10:03:34.973394Z","shell.execute_reply":"2023-05-17T10:03:34.979222Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Create dataset to pass to dataloader\n\ntrain_dataset = MakeDataset(X_train[:1000],y_train[:1000])\nval_dataset = MakeDataset(X_val[:1000], y_val[:1000])\ntest_dataset = MakeDataset(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:07:28.262558Z","iopub.execute_input":"2023-05-17T10:07:28.263384Z","iopub.status.idle":"2023-05-17T10:07:28.270781Z","shell.execute_reply.started":"2023-05-17T10:07:28.263330Z","shell.execute_reply":"2023-05-17T10:07:28.269925Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Create dataloader so getting data in epochs is easy\ntrain_loader = DataLoader(train_dataset,shuffle=True,batch_size=256)\nval_loader = DataLoader(val_dataset,shuffle=True,batch_size=256)\ntest_loader = DataLoader(test_dataset,shuffle=True,batch_size=256)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:07:28.273965Z","iopub.execute_input":"2023-05-17T10:07:28.274489Z","iopub.status.idle":"2023-05-17T10:07:28.282813Z","shell.execute_reply.started":"2023-05-17T10:07:28.274462Z","shell.execute_reply":"2023-05-17T10:07:28.281891Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## ENCODER MODULE","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    '''\n     Encoder network in which hidden size, input dimension, embedding dimension, etc \n     can be specified for training.\n    '''\n    def __init__(self,\n                    input_dimension = 72,\n                    embed_dimension = 64,\n                    hidden_dimension = 256,\n                    rnn_type = 'gru',\n                    layers = 2,\n                    bidirectional = True,\n                    dropout = 0,\n                    device = device\n                ):\n        \n        super(Encoder, self).__init__()\n\n        self.detail_parameters = {\n            'input_dimension' : input_dimension,\n            'embed_dimension' : embed_dimension,\n            'hidden_dimension' : hidden_dimension,\n            'rnn_type' : rnn_type,\n            'dropout' : dropout,\n            'layers' : layers,\n            'direction_value' : 2 if bidirectional else 1,\n            'device' : device.type,\n        }\n        \n        self.input_dimension = input_dimension\n        self.embed_dimension = embed_dimension\n        self.hidden_dimension = hidden_dimension\n        self.rnn_type = rnn_type\n        self.dropout = nn.Dropout(dropout)\n        self.layers = layers\n        self.direction_value = 2 if bidirectional else 1\n        self.device = device\n\n        self.embedding = nn.Embedding(self.input_dimension, self.embed_dimension)\n\n        if self.rnn_type == 'rnn':\n            self.enc_rnn = nn.RNN(\n                          input_size= self.embed_dimension,\n                          hidden_size= self.hidden_dimension,\n                          num_layers= self.layers,\n                          dropout = dropout,\n                          bidirectional= bidirectional)\n            \n        elif self.rnn_type == \"gru\":\n            self.enc_rnn = nn.GRU(\n                          input_size= self.embed_dimension,\n                          hidden_size= self.hidden_dimension,\n                          num_layers= self.layers,\n                          dropout = dropout,\n                          bidirectional= bidirectional)\n        elif self.rnn_type == \"lstm\":\n            self.enc_rnn = nn.LSTM(\n                          input_size= self.embed_dimension,\n                          hidden_size= self.hidden_dimension,\n                          num_layers= self.layers,\n                          dropout = dropout,\n                          bidirectional= bidirectional)\n            \n            \n    def forward(self, input, hidden, cell=None):\n        \n        # First convert sequence to embedding\n        \n        embedded = self.dropout(self.embedding(input))\n        \n        #Then choose type of rnn to run using pytorch \n        if self.rnn_type == 'lstm':\n            output,(hidden,cell) = self.enc_rnn(embedded, (hidden,cell))\n        else:\n            output, hidden = self.enc_rnn(embedded, hidden)\n\n        return output, hidden, cell\n\n    def getParams(self):\n        return self.detail_parameters\n    \n    def init_hidden(self, batch):\n        # Initialize the hidden state to zeros\n        return torch.zeros(self.direction_value*self.layers,batch,self.hidden_dimension,device=device)\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:07:28.285520Z","iopub.execute_input":"2023-05-17T10:07:28.286028Z","iopub.status.idle":"2023-05-17T10:07:28.301722Z","shell.execute_reply.started":"2023-05-17T10:07:28.285994Z","shell.execute_reply":"2023-05-17T10:07:28.300748Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## DECODER MODULE","metadata":{}},{"cell_type":"code","source":"class Decoder(nn.Module):\n    '''\n    Decoder to decode to malayalam word. It also contain different parameters\n    which is specified in the contructor. \n    '''\n    def __init__(self,\n                input_dimension = 26,\n                embed_dimension = 64,\n                hidden_dimension = 256,\n                rnn_type = 'gru',\n                layers = 2,\n                use_attention = False,\n                attention_dimension = None,\n                dropout = 0,\n                bidirectional = True,\n                device = device\n                 ):\n        \n        super(Decoder, self).__init__()\n        \n        self.detail_parameters = {\n            'input_dimension' : input_dimension,\n            'embed_dimension' : embed_dimension,\n            'hidden_dimension' : hidden_dimension,\n            'rnn_type' : rnn_type,\n            'layers' : layers,\n            'device' : device.type,\n            'dropout' : dropout\n        }\n\n        self.input_dimension = input_dimension\n        self.hidden_dimension = hidden_dimension\n        self.embed_dimension = embed_dimension\n        self.rnn_type = rnn_type\n        self.layers = layers\n        self.use_attention = use_attention\n        self.device = device\n        self.dropout = nn.Dropout(dropout)\n        self.directions = 2 if bidirectional else 1\n        self.enc_outstate_dim = attention_dimension\n        if self.use_attention:\n            self.attention_dimension = attention_dimension if attention_dimension else hidden_dimension\n        else:\n            self.attention_dimension = 0\n\n\n        self.embedding = nn.Embedding(self.input_dimension, self.embed_dimension)\n    \n        self.softmax = F.softmax\n        self.fc = nn.Sequential(\n            nn.Linear(self.hidden_dimension*self.directions, self.embed_dimension), nn.LeakyReLU(),\n            nn.Linear(self.embed_dimension, self.input_dimension),\n            )\n        \n        if self.use_attention:\n            self.W1 = nn.Linear( self.attention_dimension, self.hidden_dimension)\n            self.W2 = nn.Linear( self.hidden_dimension, self.hidden_dimension)\n            self.V = nn.Linear( self.hidden_dimension, 1)\n\n        if self.rnn_type == 'rnn':\n            self.dec_rnn = nn.RNN(input_size= self.embed_dimension + self.attention_dimension,\n                            dropout = dropout,     \n                            hidden_size= self.hidden_dimension, # previous Hidden\n                            num_layers= self.layers,\n                            bidirectional= bidirectional\n                                 )\n        elif self.rnn_type == 'gru':\n            self.dec_rnn = nn.GRU(input_size= self.embed_dimension + self.attention_dimension, # to concat attention_output\n                            hidden_size= self.hidden_dimension, # previous Hidden\n                            num_layers= self.layers,\n                            dropout = dropout,\n                            bidirectional= bidirectional\n                                 )\n        elif self.rnn_type == \"lstm\":\n            self.dec_rnn = nn.LSTM(input_size= self.embed_dimension + self.attention_dimension, # to concat attention_output\n                            hidden_size= self.hidden_dimension, # previous Hidden\n                            num_layers= self.layers,\n                            dropout = dropout,\n                            bidirectional= bidirectional\n                                  )\n\n\n    def getParams(self):\n        return self.detail_parameters\n    \n    def attention(self, hidden, enc_output):\n        \n        '''\n        It uses attention mechanism to include encoders weights to decoder.\n        '''\n        encoder_transform  = self.W1(enc_output)\n        hidden_transform =  self.W2(hidden)\n\n        score = torch.tanh(encoder_transform + hidden_transform)\n\n#         This will be our probability distribution for the attention weights (lambda)\n        attention_weights = torch.softmax(self.V(score), dim=0)\n        \n#         conext vector to be concatenated to input\n        context_vector = attention_weights * enc_output\n        context_vector = torch.sum(context_vector,dim=0)\n        context_vector = torch.sum(context_vector,dim=0).unsqueeze(0)\n        return context_vector,attention_weights\n    \n    def forward(self, input, hidden, cell=None,encoder_outputs=None):\n#         Incorporate dropout in embedding.\n        output = self.dropout(self.embedding(input))\n    \n        attention_weights = None\n#         If we are using attention, then we need to concatenate the context vector, which we obtain from attention\n        \n        if self.use_attention:\n            context,attention_weights = self.attention(hidden, encoder_outputs)\n            output = torch.cat((output,context),2)\n        \n        if self.rnn_type == 'lstm':\n            output,(hidden,cell) = self.dec_rnn(output,(hidden,cell))\n        else:\n            output, hidden = self.dec_rnn(output, hidden)\n        output = self.fc(output)\n        \n        return output, hidden, cell, attention_weights\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:07:28.302995Z","iopub.execute_input":"2023-05-17T10:07:28.303500Z","iopub.status.idle":"2023-05-17T10:07:28.324597Z","shell.execute_reply.started":"2023-05-17T10:07:28.303467Z","shell.execute_reply":"2023-05-17T10:07:28.323712Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class BeamNode(object):\n    def __init__(self, probability = 1, path_probability = 0, index = 1, hidden = None, cell = None, parent = None):\n        self.probability = probability\n        self.path_probability = path_probability\n        self.index = index\n        self.parent = parent\n        self.hidden = hidden\n        self.cell = cell\n        self.length = 0\n    \n    def __lt__(self, other):\n        return self.path_probability > other.path_probability","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:07:28.325840Z","iopub.execute_input":"2023-05-17T10:07:28.326307Z","iopub.status.idle":"2023-05-17T10:07:28.340432Z","shell.execute_reply.started":"2023-05-17T10:07:28.326275Z","shell.execute_reply":"2023-05-17T10:07:28.339310Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class BeamSearch():\n    def __init__(self, beam_width = 3):\n        self.open_list = []\n        heapq.heapify(self.open_list)\n        self.paths = []\n        self.beam_width = beam_width \n    def beamSearch(self, model, outputs,dec_hiddens,cells, predicted):\n        batch_size = outputs.shape[1]\n        \n        for i in range(batch_size):\n            with torch.no_grad():\n                model.eval()\n                output = outputs[:,i:i+1].contiguous()\n                index = output.contiguous()\n                dec_hidden = dec_hiddens[:,i:i+1,:].contiguous()\n                cell = cells[:,i:i+1,:].contiguous() if cells is not None else None\n                node = BeamNode(1,1,index,dec_hidden, cell, None)\n                heapq.heappush(self.open_list,node)\n\n                while(len(self.open_list) > 0):\n                    curr_node = heapq.heappop(self.open_list)\n                    \n                    if curr_node.length == model.output_seq_length-1:\n                        self.paths.append(curr_node)\n                        continue\n\n                    output,dec_hidden,cell,attention_weights=model.decoder.forward(curr_node.index,curr_node.hidden,curr_node.cell,None)\n                    output = model.softmax(output,dim=2)\n\n                    topk, topk_index = torch.topk(output,self.beam_width, dim = 2)\n\n                    for j in range(self.beam_width):\n                        output = topk[:,:,j]\n                        index = topk_index[:,:,j]\n                        node = BeamNode(output.item(),curr_node.path_probability * output.item(),index,dec_hidden, cell, curr_node)\n                        node.length = curr_node.length+1\n                        heapq.heappush(self.open_list,node)\n\n\n\n                    self.open_list = heapq.nsmallest(self.beam_width, self.open_list)\n\n                path = min(self.paths)\n                self.paths = []\n            \n                prev = None\n                current = path\n                while(current is not None):\n                    next = current.parent\n                    current.parent = prev\n                    prev = current\n                    current = next\n                path = prev\n                \n            model.train()\n            for t in range(1,model.output_seq_length):\n                output,dec_hidden,cell,attention_weights=model.decoder.forward(path.index,path.hidden,path.cell,None)\n                \n                predicted[t,i:i+1] = output\n                \n                path = path.parent\n                \n                \n#         return predicted","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:07:28.342065Z","iopub.execute_input":"2023-05-17T10:07:28.342548Z","iopub.status.idle":"2023-05-17T10:07:28.358418Z","shell.execute_reply.started":"2023-05-17T10:07:28.342473Z","shell.execute_reply":"2023-05-17T10:07:28.357307Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Scoring function, which is used to calculate how many words in the batch is getting 100% word match\n# This function is used in calculating accuracy\ndef scoring(y_dash , y):\n    num_sample,seq_len = y.shape\n    score = torch.sum(torch.sum(y_dash == y,axis = 1) == seq_len)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:07:28.359890Z","iopub.execute_input":"2023-05-17T10:07:28.360219Z","iopub.status.idle":"2023-05-17T10:07:28.372911Z","shell.execute_reply.started":"2023-05-17T10:07:28.360184Z","shell.execute_reply":"2023-05-17T10:07:28.371825Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## SEQUENCE TO SEQUENCE MODULE","metadata":{}},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    \n    '''\n    This class incorporate the whole transliteration model. It calls encoder and pass output of encoder\n    to decoder with or wihout attention. Parameters are specified in constructor.\n    '''\n    \n    def __init__(self, \n                 input_seq_length = 32,\n                 output_seq_length = 29,\n                 encoder_input_dimension = 29, \n                 decoder_input_dimension = 72,\n                 encoder_hidden_dimension = 256, \n                 decoder_hidden_dimension =256,\n                 encoder_embed_dimension = 256, \n                 decoder_embed_dimension = 256, \n                 bidirectional = True,\n                 encoder_num_layers = 3,\n                 decoder_num_layers = 2,\n                 rnn_type = 'lstm', \n                 dropout = 0.2, \n                 beam_width = 2,\n                 device = device,\n                 attention = False\n                ):\n        \n        \n        super(Seq2Seq, self).__init__()\n        self.detail_parameters = {\n         'input_seq_length': input_seq_length,\n         'output_seq_length' : output_seq_length,\n         'encoder_input_dimension' : encoder_input_dimension, \n         'decoder_input_dimension' : decoder_input_dimension,\n         'encoder_hidden_dimension' : encoder_hidden_dimension,\n         'encoder_embed_dimension' : encoder_embed_dimension, \n         'decoder_hidden_dimension':decoder_hidden_dimension,\n         'decoder_embed_dimension' : decoder_embed_dimension, \n         'bidirectional' : bidirectional,\n         'encoder_num_layers' : encoder_num_layers,\n         'decoder_num_layers' : decoder_num_layers,\n         'rnn_type' :rnn_type, \n         'dropout' : dropout, \n         'device' : device.type\n        }\n        self.input_seq_length = input_seq_length\n        self.output_seq_length = output_seq_length\n        self.encoder_input_dimension = encoder_input_dimension\n        self.decoder_input_dimension = decoder_input_dimension\n        self.encoder_hidden_dimension = encoder_hidden_dimension\n        self.decoder_hidden_dimension = decoder_hidden_dimension\n        self.encoder_embed_dimension = encoder_embed_dimension\n        self.decoder_embed_dimension = decoder_embed_dimension \n        self.direction = bidirectional\n        self.direction_value = 2 if bidirectional else 1\n        self.encoder_num_layers = encoder_num_layers\n        self.decoder_num_layers = decoder_num_layers\n        self.rnn_type = rnn_type \n        self.dropout = dropout\n        self.device = device\n        self.softmax = F.softmax\n        self.beam_width = beam_width\n        self.use_attention = attention\n        self.enc_dec_linear1 = nn.Linear(encoder_hidden_dimension,decoder_hidden_dimension)\n        self.enc_dec_linear2 = nn.Linear(encoder_num_layers*self.direction_value,decoder_num_layers*self.direction_value)\n        self.encoder = Encoder(input_dimension = self.encoder_input_dimension,\n                               embed_dimension = self.encoder_embed_dimension, \n                               hidden_dimension =  self.encoder_hidden_dimension,\n                               rnn_type = self.rnn_type,\n                               layers = self.encoder_num_layers,\n                               bidirectional = self.direction,\n                               dropout = self.dropout, \n                               device = self.device\n                              )\n        self.decoder = Decoder(\n                               input_dimension = self.decoder_input_dimension,\n                               embed_dimension = self.decoder_embed_dimension,\n                               hidden_dimension = self.decoder_hidden_dimension,\n                               attention_dimension = self.encoder_hidden_dimension,\n                               rnn_type = self.rnn_type,\n                               layers = self.decoder_num_layers,\n                               dropout = self.dropout, \n                               device = self.device,\n                                use_attention = self.use_attention\n                               )\n        \n    def getParams(self):\n        return self.detail_parameters\n    \n    def forward(self, input, target ,teacher_force, acc_calculate = False):\n        \n        batch_size = input.shape[0]\n        \n        enc_hidden = self.encoder.init_hidden(batch_size)\n        if self.rnn_type == 'lstm':\n            cell = self.encoder.init_hidden(batch_size)\n        else:\n            cell = None\n            \n        encoder_outputs = None\n        if self.use_attention:\n            encoder_outputs = torch.zeros(self.input_seq_length,self.direction_value*self.decoder_num_layers,batch_size,self.encoder_hidden_dimension,device=device)\n        \n        \n        for t in range(self.input_seq_length):\n            enc_output,enc_hidden, cell = self.encoder.forward(input[:,t].unsqueeze(0), enc_hidden, cell)\n            \n            if self.use_attention:\n                enc_hidden_new = enc_hidden\n                enc_hidden_new = enc_hidden_new.permute(2,1,0).contiguous()\n                enc_hidden_new = self.enc_dec_linear2(enc_hidden_new)\n        #         dec_hidden = F.relu(dec_hidden)\n                enc_hidden_new = enc_hidden_new.permute(2,1,0).contiguous()\n                encoder_outputs[t] = enc_hidden_new\n        \n        enc_last_state = enc_hidden\n        predicted = torch.zeros(self.output_seq_length, batch_size, self.decoder_input_dimension,device = self.device)\n        attn_weights = torch.zeros(self.output_seq_length, self.input_seq_length, self.direction_value*self.decoder_num_layers ,batch_size, device = self.device)\n        dec_hidden = enc_last_state\n        dec_hidden = self.enc_dec_linear1(dec_hidden)\n#         dec_hidden = F.relu(dec_hidden)\n\n\n        dec_hidden = dec_hidden.permute(2,1,0).contiguous()\n        dec_hidden = self.enc_dec_linear2(dec_hidden)\n#         dec_hidden = F.relu(dec_hidden)\n        dec_hidden = dec_hidden.permute(2,1,0).contiguous()\n        \n        if  self.rnn_type == 'lstm':\n    #         cell = cell\n    #         cell = self.enc_dec_linear1(cell)\n    # #         cell = F.relu(cell)\n            cell = cell.permute(2,1,0).contiguous()\n            cell = self.enc_dec_linear2(cell)\n    #         cell = F.relu(cell)\n            cell = cell.permute(2,1,0).contiguous()\n\n        \n        output = torch.ones(1,batch_size,dtype=torch.long, device=self.device)\n        predicted[0,:,1]=torch.ones(batch_size)\n        attention_weights = None\n        \n        \n            \n        for t in range(1,self.output_seq_length):\n            if teacher_force:\n                output,dec_hidden,cell,attention_weights=self.decoder.forward(target[:,t-1].unsqueeze(0),dec_hidden,cell,encoder_outputs)\n                predicted[t] = output.squeeze(0)\n\n            else:\n                if self.beam_width > 1 and acc_calculate:\n                    beam = BeamSearch()\n                    beam.beamSearch(self, output,dec_hidden,cell, predicted)\n                    break\n                    \n                output,dec_hidden,cell,attention_weights=self.decoder.forward(output,dec_hidden,cell,encoder_outputs)\n                predicted[t] = output.squeeze(0)\n                if self.use_attention:\n                    attn_weights[t] = attention_weights.squeeze(3)\n                output = self.softmax(output,dim=2)\n                output = torch.argmax(output,dim=2)\n\n        \n        return predicted,attn_weights","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:07:28.375369Z","iopub.execute_input":"2023-05-17T10:07:28.375955Z","iopub.status.idle":"2023-05-17T10:07:28.403572Z","shell.execute_reply.started":"2023-05-17T10:07:28.375922Z","shell.execute_reply":"2023-05-17T10:07:28.402658Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## TRAINING FOR 1 EXAMPLE CONFIGURATION","metadata":{}},{"cell_type":"code","source":"model = Seq2Seq()\nmodel.to(device)\nepochs = 10\n\ndef train(data_loader, val_loader ,epochs):\n        \n        optimizer = optim.Adam(model.parameters())\n        criterion = nn.CrossEntropyLoss()\n        # set model to train mode\n        model.train()\n        attention_weights = None\n        for epoch in tqdm(range(epochs)):\n            total_loss=0\n            train_loss = 0\n            train_score = 0\n            val_score = 0\n            val_loss = 0\n            for i, (source, target) in enumerate(data_loader):\n\n                source = source.to(device)\n                target = target.to(device)\n                \n                if i%10 == 0:\n                    print(f'batch = > {i}')\n                \n                optimizer.zero_grad()\n                \n                output,attention_weights = model.forward(source, target, epoch < epochs/2, True)                \n\n                output = output.permute(1, 0, 2)\n                expected = F.one_hot(target,num_classes = 72).float()\n                    \n                output = output.reshape(-1, 72)\n\n                expected = expected.reshape(-1,72)\n\n                loss = criterion(output, expected)\n                \n                loss.backward()  # compute gradients\n                nn.utils.clip_grad_norm_(model.parameters(),1)\n                optimizer.step()  # update parameters\n                \n                clear()\n#                 total_loss += loss.item()\n \n#                 break\n#             continue\n            with torch.no_grad():\n                model.eval()\n                for val_input, val_target in val_loader:\n                    val_input = val_input.to(device)\n                    val_target = val_target.to(device)\n                    val_output,_ = model.forward(val_input, None,False)\n                    \n                    acc_output = F.softmax(val_output,dim=2)\n                    acc_output = torch.argmax(acc_output,dim=2)\n                    acc_output = acc_output.T\n                    val_score += scoring(acc_output,val_target)\n\n                    \n                    val_output = val_output.permute(1, 0, 2)\n                    expected = F.one_hot(val_target,num_classes = 72).float()\n\n                    val_output = val_output.reshape(-1, 72)\n\n                    expected = expected.reshape(-1,72)\n\n                    \n                    loss = criterion(val_output, expected)\n                    val_loss += loss.item()\n                \n            with torch.no_grad():\n                model.eval()\n                for train_input, train_target in data_loader:\n                    train_input = train_input.to(device)\n                    train_target = train_target.to(device)\n                    train_output,_ = model.forward(train_input, None,False)\n                    \n                    acc_output = F.softmax(train_output,dim=2)\n                    acc_output = torch.argmax(acc_output,dim=2)\n                    acc_output = acc_output.T\n                    train_score += scoring(acc_output,train_target)\n\n                    \n                    train_output = train_output.permute(1, 0, 2)\n                    expected = F.one_hot(train_target,num_classes = 72).float()\n\n                    train_output = train_output.reshape(-1, 72)\n\n                    expected = expected.reshape(-1,72)\n\n                    \n                    loss = criterion(train_output, expected)\n                    train_loss += loss.item()\n                model.train()\n            \n                \n                \n            print(f'epoch {epoch}')\n            print(f'train loss => {train_loss/len(data_loader)} \\ntrain_acc => {train_score/len(data_loader.dataset)}')\n            print(f'valid loss => {val_loss/len(val_loader)} \\nvalid_acc => {val_score/len(val_loader.dataset)}')\n\ntrain(train_loader, val_loader, epochs)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T10:07:28.406483Z","iopub.execute_input":"2023-05-17T10:07:28.406885Z","iopub.status.idle":"2023-05-17T10:21:31.112878Z","shell.execute_reply.started":"2023-05-17T10:07:28.406850Z","shell.execute_reply":"2023-05-17T10:21:31.111863Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"  0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"batch = > 0\n\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:00<00:08,  1.09it/s]","output_type":"stream"},{"name":"stdout","text":"epoch 0\ntrain loss => 2.5927923917770386 \ntrain_acc => 0.0\nvalid loss => 2.037275642156601 \nvalid_acc => 0.0\nbatch = > 0\n\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [00:01<00:07,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"epoch 1\ntrain loss => 3.218457341194153 \ntrain_acc => 0.0\nvalid loss => 2.1180217266082764 \nvalid_acc => 0.0\nbatch = > 0\n\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [00:02<00:06,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"epoch 2\ntrain loss => 3.4630128741264343 \ntrain_acc => 0.0\nvalid loss => 3.5836015939712524 \nvalid_acc => 0.0\nbatch = > 0\n\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [00:03<00:05,  1.09it/s]","output_type":"stream"},{"name":"stdout","text":"epoch 3\ntrain loss => 3.6946865916252136 \ntrain_acc => 0.0\nvalid loss => 2.324721574783325 \nvalid_acc => 0.0\nbatch = > 0\n\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [00:04<00:04,  1.09it/s]","output_type":"stream"},{"name":"stdout","text":"epoch 4\ntrain loss => 3.5154075622558594 \ntrain_acc => 0.0\nvalid loss => 2.3025912642478943 \nvalid_acc => 0.0\nbatch = > 0\n\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [04:36<06:12, 93.18s/it]","output_type":"stream"},{"name":"stdout","text":"epoch 5\ntrain loss => 2.30068838596344 \ntrain_acc => 0.0\nvalid loss => 2.3071758151054382 \nvalid_acc => 0.0\nbatch = > 0\n\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [07:33<06:01, 120.38s/it]","output_type":"stream"},{"name":"stdout","text":"epoch 6\ntrain loss => 2.4458950757980347 \ntrain_acc => 0.0\nvalid loss => 2.4040867686271667 \nvalid_acc => 0.0\nbatch = > 0\n\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [09:19<03:51, 115.92s/it]","output_type":"stream"},{"name":"stdout","text":"epoch 7\ntrain loss => 2.1270986795425415 \ntrain_acc => 0.0\nvalid loss => 2.120113730430603 \nvalid_acc => 0.0\nbatch = > 0\n\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [11:07<01:53, 113.44s/it]","output_type":"stream"},{"name":"stdout","text":"epoch 8\ntrain loss => 2.3038485050201416 \ntrain_acc => 0.0\nvalid loss => 1.7376804649829865 \nvalid_acc => 0.0\nbatch = > 0\n\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J\u001b[H\u001b[2J","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [14:02<00:00, 84.25s/it] ","output_type":"stream"},{"name":"stdout","text":"epoch 9\ntrain loss => 2.535341441631317 \ntrain_acc => 0.0\nvalid loss => 1.801782876253128 \nvalid_acc => 0.0\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## TESTING AND ATTENTION PLOTS","metadata":{}},{"cell_type":"code","source":"# Get test examples, so we can plot the attention part - heatmap\n# test_input, test_labels = next(iter(test_loader))\n# model.eval()\n# test_output,_weights = model.forward(test_input.to(device), None,False)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T11:39:31.570785Z","iopub.execute_input":"2023-05-15T11:39:31.571316Z","iopub.status.idle":"2023-05-15T11:39:31.576813Z","shell.execute_reply.started":"2023-05-15T11:39:31.571272Z","shell.execute_reply":"2023-05-15T11:39:31.574986Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def getTicks(test_input, acc_output, data_index):\n    x_t = []\n    y_t = []\n    for i in range(len(test_input[data_index])):\n        if(test_input[data_index][i].item() != 0 and test_input[data_index][i].item() != 1 and test_input[data_index][i].item() != 2):\n            x_t.append(english_index_dict[test_input[data_index][i].item()])\n\n    for i in range(len(acc_output[data_index])):\n        if(acc_output[data_index][i].item() != 0 and acc_output[data_index][i].item() != 1 and acc_output[data_index][i].item() != 2):\n            y_t.append(malayalam_index_dict[acc_output[data_index][i].item()])\n            \n    return x_t, y_t\ndef plotHeatMap(test_input,acc_output,w,num_plots = 12):\n    fig, ax = plt.subplots(4, 3,figsize=(20, 20))\n    _ = plt.setp(ax)\n    for data_index in range(num_plots):\n        \n        x_t, y_t = getTicks(test_input, acc_output, data_index)\n        a = w[:,:,data_index]\n        a = a.detach().cpu().numpy()\n        a = a[1:len(y_t)+1,1:len(x_t)+1] \n        \n        \n        plt.sca(ax[data_index//3,data_index%3])\n        \n        \n        sns.heatmap(a)\n        plt.xticks(np.arange(0.5, len(x_t)+0.5), x_t)\n        mal_font = FontProperties(fname = '/kaggle/input/anjali/AnjaliOldLipi-Regular.ttf')\n        plt.yticks(np.arange(0.5, len(y_t)+0.5), y_t,fontproperties= mal_font)\n        \n        \n        \n#         plt.imshow(a,cmap='winter', interpolation='nearest')\n#         plt.colorbar()\n#         plt.xticks(np.arange(0, len(x_t)), x_t)\n#         mal_font = FontProperties(fname = '/kaggle/input/anjali/AnjaliOldLipi-Regular.ttf')\n#         plt.yticks(np.arange(0, len(y_t)), y_t,fontproperties= mal_font)\n        \n        plt.xlabel('English')\n        plt.ylabel('Malayalam')\n        plt.title(f'test image {data_index + 1}')\n        \n        \n#         plt.show()\n\n    plt.show()\n\n# if model.use_attention:\n#     acc_output = F.softmax(test_output,dim=2)\n#     acc_output = torch.argmax(acc_output,dim=2)\n#     acc_output.shape\n#     acc_output = acc_output.T\n\n#     w =  torch.mean(_weights,axis=2)\n    \n#     plotHeatMap(test_input,acc_output,w)\n# else:\n#     print(\"No Attention => No heatmap\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-15T11:39:50.024079Z","iopub.execute_input":"2023-05-15T11:39:50.024769Z","iopub.status.idle":"2023-05-15T11:39:50.039504Z","shell.execute_reply.started":"2023-05-15T11:39:50.024729Z","shell.execute_reply":"2023-05-15T11:39:50.038490Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# def printOutput(y):\n#     s=''\n#     for i in range(len(y)):\n#         if y[i] == 0 or y[i] == 1 or y[i] == 2:\n#             continue\n#         s+=malayalam_index_dict[y[i]]\n#     return s\n\n# print(printOutput(train_loader.dataset.dataset.y[1].detach().cpu().numpy()))\n# printOutput(output[1].detach().cpu().numpy())\n# malayalam_index_dict[train_loader.dataset.y[0][1]]\n","metadata":{"execution":{"iopub.status.busy":"2023-05-15T11:39:53.063069Z","iopub.execute_input":"2023-05-15T11:39:53.063440Z","iopub.status.idle":"2023-05-15T11:39:53.068064Z","shell.execute_reply.started":"2023-05-15T11:39:53.063411Z","shell.execute_reply":"2023-05-15T11:39:53.067152Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"## WANDB SWEEPS RUN FUNCTION","metadata":{}},{"cell_type":"code","source":"def runModel(model, data_loader, val_loader ,epochs):\n        \n    optimizer = optim.Adam(model.parameters())\n    criterion = nn.CrossEntropyLoss()\n\n    # set model to train mode\n    model.train()\n    train_loss_list = []\n    val_loss_list = []\n    train_accuracy_list = []\n    val_accuracy_list = []\n\n    for epoch in tqdm(range(epochs)):\n        total_loss=0\n        train_loss = 0\n        train_score = 0\n        val_score = 0\n        val_loss = 0\n        for i, (source, target) in enumerate(data_loader):\n#                 print(f'batch {i}')\n\n            source = source.to(device)\n            target = target.to(device)\n\n#                 print(target[:,1].shape)\n\n            optimizer.zero_grad()\n\n            output,_ = model.forward(source, target, epoch < epochs/2)                \n\n#                 acc_output = F.softmax(output,dim=2)\n#                 acc_output = torch.argmax(acc_output,dim=2)\n#                 acc_output = acc_output.T\n#                 train_score += scoring(acc_output,target)\n\n            output = output.permute(1, 0, 2)\n            expected = F.one_hot(target,num_classes = 72).float()\n\n            output = output.reshape(-1, 72)\n\n            expected = expected.reshape(-1,72)\n\n            loss = criterion(output, expected)\n\n            loss.backward()  # compute gradients\n            nn.utils.clip_grad_norm_(model.parameters(),1)\n            optimizer.step()  # update parameters\n\n#                 total_loss += loss.item()\n\n#                 break\n#             continue\n        with torch.no_grad():\n            model.eval()\n            for val_input, val_target in val_loader:\n                val_input = val_input.to(device)\n                val_target = val_target.to(device)\n                val_output,_ = model.forward(val_input, None,False)\n\n                acc_output = F.softmax(val_output,dim=2)\n                acc_output = torch.argmax(acc_output,dim=2)\n                acc_output = acc_output.T\n                val_score += scoring(acc_output,val_target)\n\n\n                val_output = val_output.permute(1, 0, 2)\n                expected = F.one_hot(val_target,num_classes = 72).float()\n\n                val_output = val_output.reshape(-1, 72)\n\n                expected = expected.reshape(-1,72)\n\n\n                loss = criterion(val_output, expected)\n                val_loss += loss.item()\n\n        with torch.no_grad():\n            model.eval()\n            for train_input, train_target in data_loader:\n                train_input = train_input.to(device)\n                train_target = train_target.to(device)\n                train_output,_ = model.forward(train_input, None,False)\n\n                acc_output = F.softmax(train_output,dim=2)\n                acc_output = torch.argmax(acc_output,dim=2)\n                acc_output = acc_output.T\n                train_score += scoring(acc_output,train_target)\n\n\n                train_output = train_output.permute(1, 0, 2)\n                expected = F.one_hot(train_target,num_classes = 72).float()\n\n                train_output = train_output.reshape(-1, 72)\n\n                expected = expected.reshape(-1,72)\n\n\n                loss = criterion(train_output, expected)\n                train_loss += loss.item()\n            model.train()\n\n\n\n        print(f'epoch {epoch}')\n        print(f'train loss => {train_loss/len(data_loader)} \\ntrain_acc => {train_score/len(data_loader.dataset)}')\n        print(f'valid loss => {val_loss/len(val_loader)} \\nvalid_acc => {val_score/len(val_loader.dataset)}')\n        train_loss_list.append(train_loss/len(data_loader))\n        val_loss_list.append(val_loss/len(val_loader))\n        train_accuracy_list.append(train_score/len(data_loader.dataset))\n        val_accuracy_list.append(val_score/len(val_loader.dataset))\n\n    return train_loss_list,val_loss_list,train_accuracy_list,val_accuracy_list    \n\n# model = Seq2Seq()\n# model.to(device)\n# epochs = 2\n# runModel(model, train_loader, val_loader ,epochs)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T11:40:08.225009Z","iopub.execute_input":"2023-05-15T11:40:08.225502Z","iopub.status.idle":"2023-05-15T11:40:08.259399Z","shell.execute_reply.started":"2023-05-15T11:40:08.225459Z","shell.execute_reply":"2023-05-15T11:40:08.256273Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"## WANDB SWEEPS TRAIN FUNCTION","metadata":{}},{"cell_type":"code","source":"def train_wandb():\n\n    wandb.init(project=\"dl-assignment-3-attention\", resume=True)\n\n#     num_hidden_layer = wandb.config.num_hidden_layer\n\n    wandb.run.name = f'inp_embed_{wandb.config.input_embedding}_enclayer_{wandb.config.number_of_enc_layer}_declayer_{wandb.config.number_of_dec_layer}_hidden_{wandb.config.hidden_size}_cell_{wandb.config.cell_type}_drop_{wandb.config.dropout}'\n\n    model = Seq2Seq(   \n        encoder_hidden_dimension = wandb.config.hidden_size, \n        decoder_hidden_dimension = wandb.config.hidden_size,\n        encoder_embed_dimension =  wandb.config.input_embedding, \n        decoder_embed_dimension =  wandb.config.input_embedding, \n        bidirectional = wandb.config.bidirectional,\n        encoder_num_layers = wandb.config.number_of_enc_layer,\n        decoder_num_layers = wandb.config.number_of_dec_layer,\n        rnn_type = wandb.config.cell_type, \n        dropout = wandb.config.dropout, \n        device = device,\n        attention = True\n    )\n    model.to(device)\n    epochs = 20\n    train_loss_list,val_loss_list,train_accuracy_list,val_accuracy_list = runModel(model, train_loader, val_loader, epochs)\n    #   print(val_loss_list,val_accuracy_list,train_loss_list,train_accuracy_list)\n    for i in range(len(val_loss_list)):\n        wandb.log({'validation_loss': val_loss_list[i],\n                  'training_loss': train_loss_list[i],\n                  'validation_accuracy': val_accuracy_list[i],\n                  'training_accuracy': train_accuracy_list[i]\n                  })","metadata":{"execution":{"iopub.status.busy":"2023-05-15T11:40:16.018946Z","iopub.execute_input":"2023-05-15T11:40:16.019342Z","iopub.status.idle":"2023-05-15T11:40:16.030380Z","shell.execute_reply.started":"2023-05-15T11:40:16.019308Z","shell.execute_reply":"2023-05-15T11:40:16.028558Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"## WANDB SWEEP CONFIGURATIONS","metadata":{}},{"cell_type":"code","source":"sweep_configuration = {\n    'method': 'bayes',\n    'name': 'dl-assignment-3-attention',\n    'metric': {\n        'goal': 'maximize', \n        'name': 'validation_accuracy'\n        },\n    'parameters': {\n        'input_embedding': {'values': [128, 256, 512]},\n        'number_of_enc_layer': {'values': [2, 3]},\n        'number_of_dec_layer': {'values': [2, 3]},\n        'hidden_size': {'values': [128, 256]},\n        'cell_type': {'values': ['lstm','gru','rnn']},\n        'dropout': {'values': [0.2,0.3, 0.4]},\n        'bidirectional' : {'values' : [True,False]}\n     }\n}\n\nwandb.login(key = 'c425b887e2c725018a7f3a772582610fa54ef52c')\nsweep_id = wandb.sweep(sweep=sweep_configuration, project='dl-assignment-3-attention')\nwandb.agent(sweep_id, function=train_wandb, count=100)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2023-05-12T07:54:18.817872Z","iopub.execute_input":"2023-05-12T07:54:18.818240Z","iopub.status.idle":"2023-05-12T07:57:54.283584Z","shell.execute_reply.started":"2023-05-12T07:54:18.818207Z","shell.execute_reply":"2023-05-12T07:57:54.281983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TEST ACCURACY CALCULATIONS","metadata":{}},{"cell_type":"code","source":"def testAccuracy(model, test_loader):\n    model.eval()\n    test_score = 0\n    test_loss = 0\n    optimizer = optim.Adam(model.parameters())\n    criterion = nn.CrossEntropyLoss()\n    \n    for test_input, test_target in test_loader:\n        test_input = test_input.to(device)\n        test_target = test_target.to(device)\n        test_output,_ = model.forward(test_input, None,False)\n\n        acc_output = F.softmax(test_output,dim=2)\n        acc_output = torch.argmax(acc_output,dim=2)\n        acc_output = acc_output.T\n        test_score += scoring(acc_output,test_target)\n\n\n        test_output = test_output.permute(1, 0, 2)\n        expected = F.one_hot(test_target,num_classes = 72).float()\n\n        test_output = test_output.reshape(-1, 72)\n\n        expected = expected.reshape(-1,72)\n\n\n        loss = criterion(test_output, expected)\n        test_loss += loss.item()\n        \n    print(f'test loss => {test_loss/len(test_loader)} \\ntest_acc => {test_score/len(test_loader.dataset)}')\n\n\ntestAccuracy(model, test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-05-12T10:39:53.693540Z","iopub.execute_input":"2023-05-12T10:39:53.694463Z","iopub.status.idle":"2023-05-12T10:39:55.670010Z","shell.execute_reply.started":"2023-05-12T10:39:53.694409Z","shell.execute_reply":"2023-05-12T10:39:55.668904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}